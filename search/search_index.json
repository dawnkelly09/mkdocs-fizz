{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"api-reference/api-portal/","title":"fizz.ai API reference","text":""},{"location":"get-started/batch/","title":"Batch","text":"In\u00a0[\u00a0]: Copied! <pre>import json\nfrom openai import OpenAI\n</pre> import json from openai import OpenAI In\u00a0[\u00a0]: Copied! <pre>client = OpenAI(\n    base_url=\"#\",\n    api_key=\"#\",  # Replace with your actual API key\n)\n</pre> client = OpenAI(     base_url=\"#\",     api_key=\"#\",  # Replace with your actual API key ) In\u00a0[\u00a0]: Copied! <pre>requests = [\n    {\n        \"custom_id\": \"request-1\",\n        \"method\": \"POST\",\n        \"url\": \"/v1/chat/completions\",\n        \"body\": {\n            \"model\": \"fizz/Meta-Llama-3.1-8B-Instruct-Turbo\",\n            \"messages\": [\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n                {\"role\": \"user\", \"content\": \"What is the capital of Argentina?\"},\n            ],\n            \"max_completion_tokens\": 1000,\n        },\n    },\n    {\n        \"custom_id\": \"request-2\",\n        \"method\": \"POST\",\n        \"url\": \"/v1/chat/completions\",\n        \"body\": {\n            \"model\": \"fizzai/Meta-Llama-3.3-70B-Instruct-Turbo\",\n            \"messages\": [\n                {\"role\": \"system\", \"content\": \"You are a maths tutor.\"},\n                {\"role\": \"user\", \"content\": \"Explain the Pythagorean theorem.\"},\n            ],\n            \"max_completion_tokens\": 1000,\n        },\n    },\n    {\n        \"custom_id\": \"request-4\",\n        \"method\": \"POST\",\n        \"url\": \"/v1/chat/completions\",\n        \"body\": {\n            \"model\": \"fizzai/Meta-Llama-3.3-70B-Instruct-Turbo\",\n            \"messages\": [\n                {\n                    \"role\": \"system\",\n                    \"content\": \"You are a multilingual, experienced maths tutor.\",\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": \"Explain the Pythagorean theorem in Spanish\",\n                },\n            ],\n            \"max_completion_tokens\": 1000,\n        },\n    },\n    # Additional tasks can be added here\n]\n</pre> requests = [     {         \"custom_id\": \"request-1\",         \"method\": \"POST\",         \"url\": \"/v1/chat/completions\",         \"body\": {             \"model\": \"fizz/Meta-Llama-3.1-8B-Instruct-Turbo\",             \"messages\": [                 {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},                 {\"role\": \"user\", \"content\": \"What is the capital of Argentina?\"},             ],             \"max_completion_tokens\": 1000,         },     },     {         \"custom_id\": \"request-2\",         \"method\": \"POST\",         \"url\": \"/v1/chat/completions\",         \"body\": {             \"model\": \"fizzai/Meta-Llama-3.3-70B-Instruct-Turbo\",             \"messages\": [                 {\"role\": \"system\", \"content\": \"You are a maths tutor.\"},                 {\"role\": \"user\", \"content\": \"Explain the Pythagorean theorem.\"},             ],             \"max_completion_tokens\": 1000,         },     },     {         \"custom_id\": \"request-4\",         \"method\": \"POST\",         \"url\": \"/v1/chat/completions\",         \"body\": {             \"model\": \"fizzai/Meta-Llama-3.3-70B-Instruct-Turbo\",             \"messages\": [                 {                     \"role\": \"system\",                     \"content\": \"You are a multilingual, experienced maths tutor.\",                 },                 {                     \"role\": \"user\",                     \"content\": \"Explain the Pythagorean theorem in Spanish\",                 },             ],             \"max_completion_tokens\": 1000,         },     },     # Additional tasks can be added here ] In\u00a0[\u00a0]: Copied! <pre># Save tasks to a JSONL file (newline-delimited JSON)\nfile_name = \"mybatchtest.jsonl\"\nwith open(file_name, \"w\") as file:\n    for request in requests:\n        file.write(json.dumps(request) + \"\\n\")\n</pre> # Save tasks to a JSONL file (newline-delimited JSON) file_name = \"mybatchtest.jsonl\" with open(file_name, \"w\") as file:     for request in requests:         file.write(json.dumps(request) + \"\\n\")"},{"location":"get-started/get-api-key/","title":"Generate your fizz.ai API key","text":"<p>fizz.ai provides a unique API service with an Adaptive Inference service that dynamically scales resources for high-volume, asynchronous processing, delivering lower costs than traditional batch solutions.</p> <p>This guide helps you obtain an API key, the first step to leveraging fizz.ai's powerful and cost-effective AI capabilities.</p>"},{"location":"get-started/get-api-key/#create-an-account","title":"Create an account","text":"<p>If you haven't already created an account with fizz.ai, visit the fizz.ai registration page and take the following steps:</p> <ol> <li>Enter your full name</li> <li>Provide a valid email address</li> <li>Create a secure password</li> <li>Click the Sign up button</li> </ol>"},{"location":"get-started/get-api-key/#generate-a-new-api-key","title":"Generate a new API key","text":"<p>After you've signed up or logged into the platform through the fizz.ai login page, take the following steps:</p> <ol> <li>Select API Keys on the left-hand side menu</li> <li> <p>In the API Keys section, click the Issue New API Key button</p> </li> <li> <p>Enter a descriptive name for your API key in the popup, then click Create Key</p> </li> </ol>"},{"location":"get-started/get-api-key/#copy-and-secure-your-api-key","title":"Copy and secure your API key","text":"<ol> <li>Once generated, your API key will be displayed</li> <li> <p>Copy the key and store it in a secure location, such as a password manager</p> <p>Warning</p> <p>For security reasons, you won't be able to view the key again. If lost, you will need to generate a new one.</p> </li> </ol> <p>Security tips</p> <ul> <li>Keep it secret - do not share your API key publicly or commit it to version control systems</li> <li>Use environment variables - store your API key in environment variables instead of hardcoding them</li> <li>Regenerate if compromised - if you suspect your API key has been exposed, regenerate it immediately from the API Keys section</li> </ul>"},{"location":"get-started/get-api-key/#managing-your-api-keys","title":"Managing your API keys","text":"<p>The API Key Management section allows you to efficiently manage your fizz.ai API keys. You can create, view, and delete API keys by navigating to the API Keys section. Your API keys will be listed in the API Key Management section.</p> <p>To delete an API key, take the following steps:</p> <ol> <li>Locate the API key you wish to delete in the list</li> <li>Click the trash bin icon (  ) in the Actions column</li> <li>Confirm the deletion when prompted</li> </ol> <p>Warning</p> <p>Once deleted, the API key cannot be used again and you must generate a new one if needed.</p>"},{"location":"get-started/get-api-key/#next-steps","title":"Next steps","text":"<p>Now that you have your API key, you can start integrating fizz.ai's LLMs into your applications. Refer to our Getting Started guide for detailed instructions on using the API.</p>"},{"location":"get-started/quickstart/","title":"Start using the fizz.ai API","text":"<p>The fizz.ai API provides a straightforward way to work with Large Language Models (LLMs) at scale. It is compatible with OpenAI Python library and Batch API, making it easy to integrate into your existing workflows with minimal code changes.</p> <p>Choose your preferred way to interact with the API:</p> <ul> <li>Use the OpenAI Python library (recommended)</li> <li>Make direct HTTP requests using curl</li> <li>Use any HTTP client that supports REST APIs</li> </ul> <p>This guide provides copy-and-paste examples for both Python and curl, along with detailed explanations to help you get started quickly.</p> <p>The OpenAI Python library (version 1.0.0 or higher) is recommended, which can be installed with:</p> <pre><code>pip install \"openai&gt;=1.0.0\"\n</code></pre>"},{"location":"get-started/quickstart/#get-your-api-key","title":"Get your API key","text":"<p>Navigate to the platform.fizz.ai web app and select API Keys from the left-hand menu. Create a new API key by specifying the API key name. You'll need this for all API requests.</p> <p>For step-by-step instructions, refer to the Generate your fizz.ai API key guide.</p>"},{"location":"get-started/quickstart/#batch-job-workflow-overview","title":"Batch job workflow overview","text":"<p>Working with Batch jobs in the fizz.ai API involves the following steps:</p> <ol> <li>Create Batch job files - structure your Batch requests as JSON files with the required details</li> <li>Upload Batch files - send your JSON files to the API and receive a file ID for reference</li> <li>Submit the Batch job - use the file ID to start a new Batch job</li> <li>Monitor Job progress - track the status of your Batch job to ensure it is completed successfully</li> <li>Retrieve results - after the job finishes, access and process the results as needed</li> </ol> <p>This streamlined process enables efficient handling of large-scale requests.</p>"},{"location":"get-started/quickstart/#create-batch-jobs-as-json-files","title":"Create Batch jobs as JSON files","text":"<p>To take the first step in the Batch job workflow, you'll need to assemble your Batch requests and add them to a JSON Lines file (<code>.jsonl</code>).</p> <p>Each request needs to include the following arguments:</p> <ul> <li><code>custom_id</code> string - a unique request ID that will be used to match outputs to inputs</li> <li><code>method</code> string - the HTTP method to be used for the request. Currently, only <code>POST</code> is supported</li> <li><code>url</code> string -  the <code>/v1/chat/completions</code> endpoint</li> <li> <p><code>body</code> object - a request body containing:</p> <ul> <li> <p><code>model</code> string required - name of the <code>model</code> to use, can be one of:</p> <ul> <li><code>fizzai/Meta-Llama-3.1-8B-Instruct-Turbo</code></li> <li><code>fizzai/Meta-Llama-3.1-405B-Instruct-Turbo</code></li> <li><code>fizzai/Meta-Llama-3.3-70B-Instruct-Turbo</code></li> </ul> <p>Tip</p> <p>You can see the full list of available models programmatically using the list supported models endpoint.</p> </li> <li> <p><code>messages</code> array required - a list of chat messages (<code>system</code>, <code>user</code>, or <code>assistant</code> roles)</p> </li> <li>Any optional chat completion parameters, such as <code>temperature</code>, <code>max_completion_tokens</code>, etc.</li> </ul> </li> </ul> <p>The following examples generate requests and save them in a JSONL file, ready for upload and processing.</p> Pythoncurl <pre><code>from openai import OpenAI\nimport json\n\nclient = OpenAI(\n    base_url=\"https://api.fizz.ai/v1\",\n    api_key=\"INSERT_API_KEY\",  # Replace with your actual API key\n)\n\nrequests = [\n    {\n        \"custom_id\": \"request-1\",\n        \"method\": \"POST\",\n        \"url\": \"/v1/chat/completions\",\n        \"body\": {\n            \"model\": \"fizzai/Meta-Llama-3.1-8B-Instruct-Turbo\",\n            \"messages\": [\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n                {\"role\": \"user\", \"content\": \"What is the capital of Argentina?\"},\n            ],\n            \"max_completion_tokens\": 1000,\n        },\n    },\n    {\n        \"custom_id\": \"request-2\",\n        \"method\": \"POST\",\n        \"url\": \"/v1/chat/completions\",\n        \"body\": {\n            \"model\": \"fizzai/Meta-Llama-3.3-70B-Instruct-Turbo\",\n            \"messages\": [\n                {\"role\": \"system\", \"content\": \"You are a maths tutor.\"},\n                {\"role\": \"user\", \"content\": \"Explain the Pythagorean theorem.\"},\n            ],\n            \"max_completion_tokens\": 1000,\n        },\n    },\n    {\n        \"custom_id\": \"request-4\",\n        \"method\": \"POST\",\n        \"url\": \"/v1/chat/completions\",\n        \"body\": {\n            \"model\": \"fizzai/Meta-Llama-3.3-70B-Instruct-Turbo\",\n            \"messages\": [\n                {\n                    \"role\": \"system\",\n                    \"content\": \"You are a multilingual, experienced maths tutor.\",\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": \"Explain the Pythagorean theorem in Spanish\",\n                },\n            ],\n            \"max_completion_tokens\": 1000,\n        },\n    },\n    # Additional tasks can be added here\n]\n\n# Save tasks to a JSONL file (newline-delimited JSON)\nfile_name = \"mybatchtest.jsonl\"\nwith open(file_name, \"w\") as file:\n    for request in requests:\n        file.write(json.dumps(request) + \"\\n\")\n</code></pre> <pre><code>cat &lt;&lt; EOF &gt; mybatchtest.jsonl\n{\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"fizzai/Meta-Llama-3.1-8B-Instruct-Turbo\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"What is the capital of Argentina?\"}],\"max_completion_tokens\":1000}}\n{\"custom_id\": \"request-2\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"fizzai/Meta-Llama-3.3-70B-Instruct-Turbo\", \"messages\": [{\"role\": \"system\", \"content\": \"You are an experienced maths tutor.\"}, {\"role\": \"user\", \"content\": \"Explain the Pythagorean theorem.\"}],\"max_completion_tokens\":1000}}\n{\"custom_id\": \"request-3\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"fizzai/Meta-Llama-3.1-405B-Instruct-Turbo\", \"messages\": [{\"role\": \"system\", \"content\": \"You are an astronomer.\"}, {\"role\": \"user\", \"content\": \"What is the distance between the Earth and the Moon\"}],\"max_completion_tokens\":1000}}\n{\"custom_id\": \"request-4\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"fizzai/Meta-Llama-3.3-70B-Instruct-Turbo\", \"messages\":[{\"role\": \"system\", \"content\": \"You are a multilingual, experienced maths tutor.\"}, {\"role\": \"user\", \"content\": \"Explain the Pythagorean theorem in Spanish\"}],\"max_completion_tokens\":1000}}\nEOF\n</code></pre>"},{"location":"get-started/quickstart/#upload-batch-job-files","title":"Upload Batch job files","text":"<p>Upload your JSON Lines file to the <code>files</code> endpoint along with the intended purpose of the upload. For Batch jobs, set the <code>purpose</code> value to <code>\"batch\"</code>.</p> <p>The response will contain an <code>id</code> field; save this value as you'll need it in the next step, where it's referred to as <code>input_file_id</code>.</p> <p>Note</p> <p>You can also view all your uploaded files in the Files tab of the fizz.ai platform.</p> Pythoncurl Example request<pre><code>batch_input_file = client.files.create(\n    file=open(file_name, \"rb\"),\n    purpose=\"batch\"\n)\n</code></pre> Example request<pre><code>curl -s https://api.fizz.ai/v1/files \\\n    -H \"Authorization: Bearer $API_KEY\" \\\n    -H \"Content-Type: multipart/form-data\" \\\n    -F \"file=@mybatchtest.jsonl\" \\\n    -F \"purpose=batch\"\n</code></pre> Response<pre><code>{\n    \"id\": \"myfile-123\",\n    \"bytes\": 2797,\n    \"created_at\": \"1733832768\",\n    \"filename\": \"mybatchtest.jsonl\",\n    \"object\": \"file\",\n    \"purpose\": \"batch\"\n}\n</code></pre>"},{"location":"get-started/quickstart/#submit-a-batch-job","title":"Submit a Batch job","text":"<p>Next, submit a Batch job by calling the <code>batches</code> endpoint and providing the <code>id</code> of the uploaded Batch job file (from the previous section) as the <code>input_file_id</code>, and additional parameters to specify the job's configuration.</p> <p>The response includes an <code>id</code> that can be used to monitor the job's progress, as demonstrated in the next section.</p> Pythoncurl Example request<pre><code>batch_request = client.batches.create(\n    input_file_id=batch_input_file.id,\n    endpoint=\"/v1/chat/completions\",\n    completion_window=\"24h\",\n)\n</code></pre> Example request<pre><code>curl -s https://api.fizz.ai/v1/batches \\\n    -H \"Authorization: Bearer $API_KEY\" \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\n    \"input_file_id\": \"myfile-123\",\n    \"endpoint\": \"/v1/chat/completions\",\n    \"completion_window\": \"24h\"\n    }'\n</code></pre> Response<pre><code>{\n    \"id\": \"mybatch-123\",\n    \"completion_window\": \"24h\",\n    \"created_at\": 1733832777,\n    \"endpoint\": \"/v1/chat/completions\",\n    \"input_file_id\": \"myfile-123\",\n    \"object\": \"batch\",\n    \"status\": \"validating\",\n    \"cancelled_at\": null,\n    \"cancelling_at\": null,\n    \"completed_at\": null,\n    \"error_file_id\": null,\n    \"errors\": null,\n    \"expired_at\": null,\n    \"expires_at\": 1733919177,\n    \"failed_at\": null,\n    \"finalizing_at\": null,\n    \"in_progress_at\": null,\n    \"metadata\": {},\n    \"output_file_id\": null,\n    \"request_counts\": {\n        \"completed\": 0,\n        \"failed\": 0,\n        \"total\": 0\n    }\n}\n</code></pre>"},{"location":"get-started/quickstart/#monitor-job-progress","title":"Monitor job progress","text":"<p>To monitor your Batch job's progress, make periodic requests to the <code>batches</code> endpoint using the <code>id</code> of the Batch request (from the previous section) as the <code>batch_id</code> to check its status. The job is complete when the <code>status</code> field returns <code>\"completed\"</code>.</p> <p>To see a complete list of the supported statuses, refer to the Retrieve a batch API reference page.</p> <p>Note</p> <p>You can also monitor jobs in the Batch tab of the fizz.ai platform UI.</p> Pythoncurl Example request<pre><code>import time\n\n# Poll the Batch status until it's complete\nwhile True:\n    batch_status = client.batches.retrieve(batch_request.id)\n    print(\"Batch status: {}\".format(batch_status.status))\n    print(\n        f\"Completed tasks: {batch_status.request_counts.completed} / {batch_status.request_counts.total}\"\n    )\n\n    if batch_status.status.lower() in [\"completed\", \"failed\", \"cancelled\"]:\n        break\n\n    time.sleep(10)  # Wait for 10 seconds before checking again\n</code></pre> Example request<pre><code>curl -s https://api.fizz.ai/v1/batches/mybatch-123 \\\n    -H \"Authorization: Bearer $API_KEY\" \\\n    -H \"Content-Type: application/json\"\n</code></pre> Response<pre><code>{\n    \"id\": \"mybatch-123\",\n    \"object\": \"batch\",\n    \"endpoint\": \"/v1/chat/completions\",\n    \"errors\": null,\n    \"input_file_id\": \"myfile-123\",\n    \"completion_window\": \"24h\",\n    \"status\": \"completed\",\n    \"output_file_id\": \"myfile-123-output\",\n    \"error_file_id\": null,\n    \"created_at\": \"1733832777\",\n    \"in_progress_at\": \"1733832777\",\n    \"expires_at\": \"1733919177\",\n    \"finalizing_at\": \"1733832781\",\n    \"completed_at\": \"1733832781\",\n    \"failed_at\": null,\n    \"expired_at\": null,\n    \"cancelling_at\": null,\n    \"cancelled_at\": null,\n    \"request_counts\": {\n        \"total\": 4,\n        \"completed\": 4,\n        \"failed\": 0\n    },\n    \"metadata\": {}\n}\n</code></pre>"},{"location":"get-started/quickstart/#retrieve-results","title":"Retrieve results","text":"<p>To retrieve the content of your Batch jobs output file, send a request to the <code>files</code> endpoint specifying the <code>output_file_id</code>, which is returned from querying the Batch's status (from the previous section).</p> <p>The output file will be a JSONL file, where each line contains the <code>custom_id</code> from your input file request and the corresponding response.</p> Pythoncurl Example request<pre><code># Check if the Batch completed successfully\nif batch_status.status.lower() == \"completed\":\n    # Retrieve the results\n    result_file_id = batch_status.output_file_id\n    results = client.files.content(result_file_id).content\n\n    # Save results to a file\n    result_file_name = \"batch_results.jsonl\"\n    with open(result_file_name, \"wb\") as file:\n        file.write(results)\n    print(f\"Results saved to {result_file_name}\")\nelse:\n    print(f\"Batch failed with status: {batch_status.status}\")\n</code></pre> Example request<pre><code>curl -s https://api.fizz.ai/v1/files/fizz-output-file-123/content \\\n    -H \"Authorization: Bearer $API_KEY\" &gt; batch_output.jsonl\n</code></pre>"},{"location":"get-started/quickstart/#list-all-batch-jobs","title":"List all Batch jobs","text":"<p>To list all of your Batch jobs, send a request to the <code>batches</code> endpoint without specifying a <code>batch_id</code>. To constrain the query response, you can also use a <code>limit</code> parameter.</p> Pythoncurl Example request<pre><code>from openai import OpenAI\n\n# Configure OpenAI client\nclient = OpenAI(\n    base_url=\"https://api.fizz.ai/v1\", \n    api_key=\"INSERT_API_KEY\" # Replace with your actual API key\n)\n\nprint(client.batches.list(limit=2).to_dict())\n</code></pre> Example request<pre><code>curl -s https://api.fizz.ai/v1/batches \\\n    -H \"Authorization: Bearer $API_KEY\"\n</code></pre> Response<pre><code>{\n\"object\": \"list\",\n\"data\": [\n    {\n    \"id\": \"mybatch-123\",\n    \"object\": \"batch\",\n    \"endpoint\": \"/v1/chat/completions\",\n    \"errors\": null,\n    \"input_file_id\": \"myfile-123\",\n    \"completion_window\": \"24h\",\n    \"status\": \"completed\",\n    \"output_file_id\": \"myfile-123-output\",\n    \"error_file_id\": null,\n    \"created_at\": \"1733832777\",\n    \"in_progress_at\": \"1733832777\",\n    \"expires_at\": \"1733919177\",\n    \"finalizing_at\": \"1733832781\",\n    \"completed_at\": \"1733832781\",\n    \"failed_at\": null,\n    \"expired_at\": null,\n    \"cancelling_at\": null,\n    \"cancelled_at\": null,\n    \"request_counts\": {\n        \"total\": 4,\n        \"completed\": 4,\n        \"failed\": 0\n    },\n    \"metadata\": {}\n    },\n{ ... },\n],\n\"first_id\": \"mybatch-123\",\n\"last_id\": \"mybatch-789\",\n\"has_more\": false,\n\"count\": 1,\n\"page\": 1,\n\"page_count\": -1,\n\"items_per_page\": 9223372036854775807\n}\n</code></pre>"},{"location":"get-started/quickstart/#cancel-a-batch-job","title":"Cancel a Batch job","text":"<p>To cancel a Batch job currently in progress, send a request to the <code>cancel</code> endpoint with your <code>batch_id</code>. Note that cancellation may take up to 10 minutes to complete, during which time the status will show as <code>cancelling</code>. Once complete, the status will show as <code>cancelled</code>.</p> Pythoncurl Example<pre><code>from openai import OpenAI\n\nclient = OpenAI(\n    base_url=\"https://api.fizz.ai/v1\",  \n    api_key=\"INSERT_API_KEY\" # Replace with your actual API key\n)\nclient.batches.cancel(\"mybatch-123\") # Replace with your Batch id\n</code></pre> Example<pre><code>curl -s https://api.fizz.ai/v1/batches/$BATCH_ID/cancel \\\n    -H \"Authorization: Bearer $API_KEY\" \\\n    -H \"Content-Type: application/json\" \\\n    -X POST\n</code></pre> Response<pre><code>{\n    \"id\": \"mybatch-123\",\n    \"object\": \"batch\",\n    \"endpoint\": \"/v1/chat/completions\",\n    \"errors\": null,\n    \"input_file_id\": \"myfile-123\",\n    \"completion_window\": \"24h\",\n    \"status\": \"cancelling\",\n    \"output_file_id\": \"myfile-123-output\",\n    \"error_file_id\": null,\n    \"created_at\": \"1730821906\",\n    \"in_progress_at\": \"1730821911\",\n    \"expires_at\": \"1730821906\",\n    \"finalizing_at\": null,\n    \"completed_at\": null,\n    \"failed_at\": null,\n    \"expired_at\": null,\n    \"cancelling_at\": \"1730821906\",\n    \"cancelled_at\": null,\n    \"request_counts\": {\n        \"total\": 3,\n        \"completed\": 3,\n        \"failed\": 0\n    },\n    \"metadata\": {}\n}\n</code></pre>"},{"location":"get-started/quickstart/#summary","title":"Summary","text":"<p>Congratulations! You now have all the tools needed to work with the fizz.ai Batch API. In this guide, you've learned how to:</p> <ul> <li>Prepare and submit Batch jobs with structured request inputs</li> <li>Track your jobs' progress in real-time</li> <li>Retrieve and handle job results</li> <li>View and manage your Batch jobs</li> <li>Cancel jobs when needed</li> <li>View supported models</li> </ul> <p>The fizz.ai Batch API is designed to efficiently and reliably handle your large-scale LLM workloads. Do you have questions or suggestions? The support team would love to hear from you.</p>"}]}